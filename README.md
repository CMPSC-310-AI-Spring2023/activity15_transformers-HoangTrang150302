[![Review Assignment Due Date](https://classroom.github.com/assets/deadline-readme-button-24ddc0f5d75046c5622901739e7c5dd533143b0c8e959d652212380cedb1ea36.svg)](https://classroom.github.com/a/ymop5HUw)
# CMPSC 310 Activity 15

## Deadline: April 12 by 9:50am

## Assignment

 For this activity follow [Neural machine translation with a Transformer and Keras](https://www.tensorflow.org/text/tutorials/transformer).

## Submission

Submit completed Colab notebook showing generated output.

## Explain transformer

- Transformer is significant because it is good at modeling sequential data such as natural languages.

- Transformers replaced recurrence with attention, so computations can happen simultaneously.

- Transformers are able to capture distant or long-range contexts, because attention allows each location have access to the entire input. In RNN and CNN, the information need to go through many processing steps which makes it harder to learn.
